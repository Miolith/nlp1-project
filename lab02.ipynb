{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c41c1d",
   "metadata": {},
   "source": [
    "# NLP Project\n",
    "## Lab 02\n",
    "Nelson VICEL--FARAH\\\n",
    "Karen KASPAR\\\n",
    "Romain BRAND"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5840f",
   "metadata": {},
   "source": [
    "## The datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453407a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e6d15fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/miolith/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84654fc2fa8b43a7afd3f3f0f62f4811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f955c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5b0fa",
   "metadata": {},
   "source": [
    "### 1. How many splits does the dataset has? (1 point)\n",
    "#### On observe que le dataset IMDb a 3 splits différents\n",
    "### 2. How big are these splits? (1 point)\n",
    "#### Le **train** split a 25 000 lignes, **test** 25 000 lignes et **unsupervised** avec 50 000 lignes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73542254",
   "metadata": {},
   "source": [
    "### 3. What is the proportion of each class on the supervised splits? (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbacfc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(imdb_dataset[\"train\"])\n",
    "\n",
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a42eebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(imdb_dataset[\"test\"])\n",
    "\n",
    "test_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1767368f",
   "metadata": {},
   "source": [
    "#### Il y a 50% de chaque classe dans chaque split supervisé. Le dataset est équilibré."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63d72f",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3d9cf",
   "metadata": {},
   "source": [
    "### 1. (2 points) Take a look at the data and create an adapted preprocessing function.\n",
    "\n",
    "On a fait un transformer sklearn personnalisé pour pouvoir l'ajouter directement dans la pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4324feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, text_list, label = None):\n",
    "        new_text_list = text_list.copy()\n",
    "        # i. Lower case the text\n",
    "        new_text_list = new_text_list.str.lower()\n",
    "        \n",
    "        # ii. Remove punctuation\n",
    "        new_text_list = new_text_list.str.replace('[{}]'.format(punctuation), ' ', regex=True)\n",
    "        \n",
    "        return new_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f730e",
   "metadata": {},
   "source": [
    "### 2. (4 points) Implement and train a naive Bayes classifier on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa542ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;customtransformer&#x27;, CustomTransformer()),\n",
       "                (&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;customtransformer&#x27;, CustomTransformer()),\n",
       "                (&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('customtransformer', CustomTransformer()),\n",
       "                ('countvectorizer', CountVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(CustomTransformer(), CountVectorizer(), MultinomialNB())\n",
    "\n",
    "pipe.fit(train_df[\"text\"], train_df[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cba1da",
   "metadata": {},
   "source": [
    "### 3. (1 point) Report the accuracy on both training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe3bea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the train set is 0.89808\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = pipe.score(train_df[\"text\"], train_df[\"label\"])\n",
    "print('The accuracy on the train set is', train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d201eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the test set is 0.8136\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = pipe.score(test_df[\"text\"], test_df[\"label\"])\n",
    "print('The accuracy on the test set is', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7519a11e",
   "metadata": {},
   "source": [
    "### 4. (1 point) Why is accuracy a sufficient measure of evaluation here?\n",
    "#### La précision est suffisante dans notre cas car le dataset est équilibré, donc on peut facilement juger qu'une précision supérieure à 50% est meilleure qu'un algorithme aléatoire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038daa7",
   "metadata": {},
   "source": [
    "### 6. (1 point) Take at least 2 wrongly classified example from the test set and try explaining why the model failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dca4d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "24995    0\n",
       "24996    0\n",
       "24997    1\n",
       "24998    0\n",
       "24999    0\n",
       "Name: prediction, Length: 25000, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"prediction\"] = pipe.predict(test_df[\"text\"])\n",
    "test_df[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "402f43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_sample1 = test_df[(test_df[\"prediction\"] == 1) & (test_df[\"label\"] == 0)].iloc[1,:][\"text\"]\n",
    "failed_sample2 = test_df[(test_df[\"prediction\"] == 0) & (test_df[\"label\"] == 1)].iloc[1,:][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6636864",
   "metadata": {},
   "source": [
    "#### Cet exemple est un faux positif. L'auteur est vraisemblablement ironique, ce qui aurait pu tromper l'algorithme de NaiveBayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b31bec26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ben, (Rupert Grint), is a deeply unhappy adolescent, the son of his unhappily married parents. His father, (Nicholas Farrell), is a vicar and his mother, (Laura Linney), is ... well, let's just say she's a somewhat hypocritical soldier in Jesus' army. It's only when he takes a summer job as an assistant to a foul-mouthed, eccentric, once-famous and now-forgotten actress Evie Walton, (Julie Walters), that he finally finds himself in true 'Harold and Maude' fashion. Of course, Evie is deeply unhappy herself and it's only when these two sad sacks find each other that they can put their mutual misery aside and hit the road to happiness.<br /><br />Of course it's corny and sentimental and very predictable but it has a hard side to it, too and Walters, who could sleep-walk her way through this sort of thing if she wanted, is excellent. It's when she puts the craziness to one side and finds the pathos in the character, (like hitting the bottle and throwing up in the sink), that she's at her best. The problem is she's the only interesting character in the film (and it's not because of the script which doesn't do anybody any favours). Grint, on the other hand, isn't just unhappy; he's a bit of a bore as well while Linney's starched bitch is completely one-dimensional. (Still, she's got the English accent off pat). The best that can be said for it is that it's mildly enjoyable - with the emphasis on the mildly.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_sample1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b57578",
   "metadata": {},
   "source": [
    "#### Cet exemple est un faux négatif. Ce commentaire est une description de l'oeuvre plutôt qu'une opinion explicite, les adjectifs qualificatifs sont rarement utilisés pour expliciter si le film a été apprécié ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d41c4c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This was a bold movie to hit Indian cinemas when it was released. The first movie to perhaps openly depict lesbian tendencies amongst Indian women. The leading actress of Indian cinema Shabana Azmi added substance to the movie with her hot passionate scenes with Nandita Das.<br /><br />The movie oozed with sexuality and the director used sex in the best way possible. The sex was not for erotic purposes but was in the context of the movie. The scene where Nandita Das loses her virginity to her husband certainly was the first of its kind in Indian cinemas.<br /><br />Good acting by all the actors especially Nandita Das amidst criticism from the Indian public'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_sample2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d4f69",
   "metadata": {},
   "source": [
    "![alt text](https://media.discordapp.net/attachments/465505646607859714/1026859583853051985/memenlp.png?width=311&height=400 \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5a33d",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cada01",
   "metadata": {},
   "source": [
    "### 1. (2 points) Add stemming or lemmatization to your pretreatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db4c1f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/miolith/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740f3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "re_word = re.compile(r\"^\\w+$\")\n",
    "def stemming(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed = [stemmer.stem(word) for word in word_tokenize(text) if re_word.match(word)]\n",
    "    return \" \".join(stemmed)\n",
    "\n",
    "class StemmingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, text_list, label = None):\n",
    "        new_text_list = text_list.copy()\n",
    "        \n",
    "        return new_text_list.apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5a6d4",
   "metadata": {},
   "source": [
    "### 2. (1 point) Train and evaluate your model again with these pretreatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c57aa1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;customtransformer&#x27;, CustomTransformer()),\n",
       "                (&#x27;stemmingtransformer&#x27;, StemmingTransformer()),\n",
       "                (&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;customtransformer&#x27;, CustomTransformer()),\n",
       "                (&#x27;stemmingtransformer&#x27;, StemmingTransformer()),\n",
       "                (&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StemmingTransformer</label><div class=\"sk-toggleable__content\"><pre>StemmingTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('customtransformer', CustomTransformer()),\n",
       "                ('stemmingtransformer', StemmingTransformer()),\n",
       "                ('countvectorizer', CountVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_stem = make_pipeline(CustomTransformer(), StemmingTransformer(), CountVectorizer(), MultinomialNB())\n",
    "\n",
    "pipe_stem.fit(train_df[\"text\"], train_df[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f9838e",
   "metadata": {},
   "source": [
    "### 3. (1 point) Are the results better or worse? Try explaining why the accuracy changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a011923e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the train set is 0.88404\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = pipe_stem.score(train_df[\"text\"], train_df[\"label\"])\n",
    "print('The accuracy on the train set is', train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2eb47b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the train set is 0.80616\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = pipe_stem.score(test_df[\"text\"], test_df[\"label\"])\n",
    "print('The accuracy on the train set is', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6895a2c",
   "metadata": {},
   "source": [
    "Avec le stemming, la précision a diminué de 1% du fait que cette méthode implique potentiellement de la perte d'information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7c2257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
